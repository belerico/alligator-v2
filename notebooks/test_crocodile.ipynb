{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped collection: input_data\n",
      "All unwanted collections have been dropped.\n",
      "Onboarding -1 rows for dataset '8956b58fdaa345589f289a2f42cfef9c', table 'imdb_top_100'\n",
      "Chunk 1: Processed 100 rows (total: 100) (13777.7 rows/sec)\n",
      "Data onboarding complete for dataset '8956b58fdaa345589f289a2f42cfef9c' and table 'imdb_top_100'\n",
      "Onboarded 100 rows in 0.01 seconds (13609.9 rows/sec)\n",
      "Found 100 tasks to process.\n",
      "Worker 0 processing 100 tasks...\n",
      "Worker 0 processing 0 tasks...\n",
      "No more tasks to process.\n",
      "Worker 1 processing 0 tasks...\n",
      "No more tasks to process.\n",
      "Worker 2 processing 0 tasks...\n",
      "No more tasks to process.\n",
      "Worker 3 processing 0 tasks...\n",
      "No more tasks to process.\n",
      "Worker 4 processing 0 tasks...\n",
      "No more tasks to process.\n",
      "Worker 5 processing 0 tasks...\n",
      "No more tasks to process.\n",
      "ML ranking for stage rank progress: 0/100 documents\n",
      "ML ranking for stage rank progress: 0/100 documents\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "ML ranking for stage rank progress: 52/100 documentsML ranking for stage rank progress: 48/100 documents\n",
      "\n",
      "ML ranking for stage rank complete: 52/100 documentsML ranking for stage rank complete: 48/100 documents\n",
      "\n",
      "Computing type-frequency features by processing first 100 documents\n",
      "Computed type frequencies from 100 documents\n",
      "ML ranking for stage rerank progress: 0/100 documents\n",
      "ML ranking for stage rerank progress: 0/100 documents\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "ML ranking for stage rerank progress: 40/100 documents\n",
      "ML ranking for stage rerank complete: 40/100 documents\n",
      "ML ranking for stage rerank progress: 60/100 documents\n",
      "ML ranking for stage rerank complete: 60/100 documents\n",
      "All tasks have been processed.\n",
      "Streaming 100 documents to CSV...\n",
      "Processed 100/100 rows...\n",
      "Results saved to './tables/imdb_top_100_output.csv'. Total rows: 100\n",
      "Elapsed time: 3.1709219600015786\n",
      "Entity linking process completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import IPython\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from alligator import Alligator\n",
    "\n",
    "IPython.display.clear_output(wait=True)\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = \"./tables/imdb_top_100.csv\"\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient(\"mongodb://gator-mongodb:27017/\")\n",
    "# Drop the entire crocodile_db database\n",
    "# client.drop_database(\"crocodile_db\")\n",
    "db = client[\"alligator_db\"]\n",
    "\n",
    "# Drop all collections except 'bow_cache' and 'candidate_cache'\n",
    "collections_to_keep = [\"candidate_cache\", \"literal_cache\", \"object_cache\"]\n",
    "all_collections = db.list_collection_names()\n",
    "\n",
    "for collection in all_collections:\n",
    "    if collection not in collections_to_keep:\n",
    "        db[collection].drop()\n",
    "        print(f\"Dropped collection: {collection}\")\n",
    "\n",
    "print(\"All unwanted collections have been dropped.\")\n",
    "\n",
    "# Create an instance of the Alligator class\n",
    "gator = Alligator(\n",
    "    input_csv=file_path,\n",
    "    entity_retrieval_endpoint=os.environ[\"ENTITY_RETRIEVAL_ENDPOINT\"],\n",
    "    entity_retrieval_token=os.environ[\"ENTITY_RETRIEVAL_TOKEN\"],\n",
    "    object_retrieval_endpoint=os.environ[\"OBJECT_RETRIEVAL_ENDPOINT\"],\n",
    "    literal_retrieval_endpoint=os.environ[\"LITERAL_RETRIEVAL_ENDPOINT\"],\n",
    "    max_workers=1,\n",
    "    candidate_retrieval_limit=10,\n",
    "    max_candidates_in_result=3,\n",
    "    batch_size=256,\n",
    "    columns_type={\n",
    "        \"NE\": {\"0\": \"OTHER\", \"7\": \"OTHER\"},\n",
    "        \"LIT\": {\"1\": \"NUMBER\", \"2\": \"NUMBER\", \"3\": \"STRING\", \"4\": \"NUMBER\", \"5\": \"STRING\"},\n",
    "        \"IGNORED\": [\"6\", \"9\", \"10\", \"7\", \"8\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "# Run the entity linking process\n",
    "tic = time.perf_counter()\n",
    "await gator.run()\n",
    "toc = time.perf_counter()\n",
    "print(\"Elapsed time:\", toc - tic)\n",
    "print(\"Entity linking process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from alligator.fetchers import ObjectFetcher, LiteralFetcher\n",
    "\n",
    "object_retrieval_endpoint = os.environ[\"OBJECT_RETRIEVAL_ENDPOINT\"]\n",
    "literal_retrieval_endpoint = os.environ[\"LITERAL_RETRIEVAL_ENDPOINT\"]\n",
    "entity_retrieval_token = os.environ[\"ENTITY_RETRIEVAL_TOKEN\"]\n",
    "\n",
    "o = ObjectFetcher(object_retrieval_endpoint, entity_retrieval_token)\n",
    "objs = await o.fetch_objects([\"Q90\", \"Q60\"])\n",
    "\n",
    "l = LiteralFetcher(literal_retrieval_endpoint, entity_retrieval_token)\n",
    "lits = await l.fetch_literals([\"Q90\"])\n",
    "\n",
    "print(objs)\n",
    "print(lits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
